{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37.9, 21.4, 12.7, 19.9, 22.5, 32.7, 23.2, 21.5, 20.5, 33.3, 23.1,\n",
       "       20. , 50. , 25. , 20.2, 16.4, 22.4, 20.4, 18.4, 37.3, 23.1, 34.7,\n",
       "       33.1, 28.7, 15.6, 18.2, 17.2, 31.5, 26.6, 24.1, 22.3, 19.5, 36.1,\n",
       "       17.6, 33.4,  8.8,  9.7, 13.4, 39.8, 24.4, 17.8, 24.3, 24. , 23.1,\n",
       "       13.1, 16.7, 22.8, 27.5, 14.6, 13.4, 11. , 19.4, 15. , 44.8, 29.6,\n",
       "       12.3, 24.6, 10.9, 28. , 30.8, 15.4, 18. , 35.2, 11.5, 19.5, 24.8,\n",
       "       22.2, 20.1, 15.2, 50. , 17.1, 23. , 12. , 22. , 20. , 20.3, 17.2,\n",
       "       37.2,  5. , 24.5, 18.9, 24.5, 24.8, 21.6,  7. , 17.7, 12.8, 14.9,\n",
       "       18.3, 15.6, 19.9, 22.2, 16.7, 32.5, 25.1, 30.1, 16.1, 20.7, 46. ,\n",
       "       22.3, 23. , 11.9, 23.3, 23.2, 22. , 10.5, 17.2, 29.8, 29. , 17.3,\n",
       "       20.6, 20.1, 20.6, 17.8, 25. , 22.6, 18.7, 11.3,  9.6, 17.8, 23.9,\n",
       "       38.7, 21.2, 25. , 28.5, 24. , 20.6,  5. , 22.9, 18.4, 31. , 36. ,\n",
       "       20.8, 13.3, 23.2, 28.2, 43.8, 26.6, 23.9, 23.9, 27.9, 19.1, 30.5,\n",
       "        8.3,  8.5, 16.5, 23.8, 19.6, 22.2, 24.3, 32. , 26.2, 21.7, 20.6,\n",
       "       20. ,  7.5, 33. , 14.9, 14.8, 50. , 26.4, 19.7, 15.6, 25. , 22.7,\n",
       "       15.2, 37. , 31.6, 19.3, 15.6,  8.1, 23.7, 32. , 42.8, 21.4, 31.6,\n",
       "       14.1, 27.5, 22.5, 13.6,  7.4, 18.8, 50. , 30.1, 10.4, 14.5, 41.7,\n",
       "       14.6, 23.7, 16.1, 32.2, 14.2, 50. , 23. , 19.1, 15. , 15. , 18.5,\n",
       "       10.4, 24.7, 36.5, 21.7, 48.3, 27.5, 12.6, 36.2, 29.9, 43.5, 19.6,\n",
       "       19.4, 11.8, 34.9, 17.8, 14. , 16.2, 20. , 21.1, 16.6, 18.9, 14.5,\n",
       "       19.3, 25. , 18.9, 31.1,  8.3, 17.9, 22.1, 19.5, 20.6, 20.9, 20.4,\n",
       "       16.8, 12.1, 15.7, 32.9, 34.9, 14.3, 11.7, 30.1, 25. , 29.1, 33.1,\n",
       "       36.2, 24.4, 22.9, 50. , 15.2, 46.7,  5.6, 13.8,  7.2, 27.1, 26.5,\n",
       "       18.5, 22. , 21.9, 18.1, 16. , 17.5, 12.5, 28.7, 18.7, 23.1, 13.3,\n",
       "       21. , 17. ,  8.4, 13.2, 22.8, 23.8, 20.4, 45.4, 19.2, 22.9,  9.5,\n",
       "       20.1, 18.5, 19.4, 30.7, 18.5, 50. , 27.5, 33.2, 31.7, 18.4, 27.9,\n",
       "       18.3, 20.2, 23.1,  8.4, 48.8, 13.8, 25.3, 31.2, 16.5, 18.8, 24.4,\n",
       "       16.2, 13.4, 31.5, 23.7, 21.9, 25. , 20. , 26.6, 22.9, 19.9, 23.7,\n",
       "       24.5, 37.6, 13.5, 19.5, 24.4, 34.6, 22.2, 24.7, 14.1, 33.2, 19.3,\n",
       "       19.8, 50. , 13.1, 19. , 19.1, 36.4, 35.4, 23.5,  7.2, 15.3, 21.8,\n",
       "       17.4, 22.6,  8.5, 24.8, 18.2, 21.7, 17.4, 50. , 27.1,  6.3, 24.2,\n",
       "       24.3, 19.4, 17.4,  8.7, 17.8, 19.6, 43.1, 20.1, 10.8, 22. , 21.2,\n",
       "       24.1, 28.7, 16.6,  7. , 22.7, 27. , 13.5, 16.1, 21.4, 24.6, 20.1,\n",
       "       50. , 12.7, 23.1, 21.1, 13.3, 13.9, 21.7, 23.9, 20.3, 13.6, 20.8,\n",
       "       50. , 14.3, 20.8, 22.6, 50. ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "data = np.genfromtxt(\"training_boston_x_y_train.csv\",delimiter=',')\n",
    "X_test = np.genfromtxt(\"test_boston_x_test.csv\",delimiter=',')\n",
    "X_train = data[:,0:13]\n",
    "y_train = data[:,13]\n",
    "new_column = np.ones(data.shape[0])\n",
    "X_train = np.insert(X_train,X_train.shape[1],new_column,axis=1)\n",
    "new_column_2 = np.ones(X_test.shape[0])\n",
    "X_test = np.insert(X_test,X_test.shape[1],new_column_2,axis=1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(learning_rate,m):\n",
    "    m_slope = np.zeros((data.shape[1]))\n",
    "    M = len(data)\n",
    "    for i in range(len(data[0])):\n",
    "        for j in range(len(data)):\n",
    "            x=X_train[j]\n",
    "            m_slope[i] += (-2/M)*(y_train[j]-(m*x).sum())*(x[i])\n",
    "    m = m - learning_rate*m_slope\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(m):\n",
    "    cost = 0;\n",
    "    for i in range(len(data)):\n",
    "        cost += ((y_train[i]-(m*X_train[i]).sum())**2)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14,)\n",
      "Cost:  131104.06306396663\n",
      "Cost:  86154.80568203104\n",
      "Cost:  58205.337116257644\n",
      "Cost:  40597.936483832986\n",
      "Cost:  29450.125605373174\n",
      "Cost:  22361.70913618516\n",
      "Cost:  17834.221378864524\n",
      "Cost:  14927.919320337653\n",
      "Cost:  13051.30845883528\n",
      "Cost:  11830.878602589512\n",
      "Cost:  11030.067288912258\n",
      "Cost:  10498.62973056055\n",
      "Cost:  10140.8860028069\n",
      "Cost:  9895.740213576677\n",
      "Cost:  9724.069810939125\n",
      "Cost:  9600.745286535608\n",
      "Cost:  9509.567994762898\n",
      "Cost:  9440.05203738755\n",
      "Cost:  9385.374324535\n",
      "Cost:  9341.066266829168\n",
      "Cost:  9304.17723038318\n",
      "Cost:  9272.738629764306\n",
      "Cost:  9245.419930202728\n",
      "Cost:  9221.30735079291\n",
      "Cost:  9199.76114387629\n",
      "Cost:  9180.323275563234\n",
      "Cost:  9162.657491118287\n",
      "Cost:  9146.510228984353\n",
      "Cost:  9131.684986377584\n",
      "Cost:  9118.025386670108\n",
      "Cost:  9105.403893968061\n",
      "Cost:  9093.714207102865\n",
      "Cost:  9082.86606286446\n",
      "Cost:  9072.78162665939\n",
      "Cost:  9063.392937331264\n",
      "Cost:  9054.6400588797\n",
      "Cost:  9046.469711924003\n",
      "Cost:  9038.83423548803\n",
      "Cost:  9031.690780121327\n",
      "Cost:  9025.000666207181\n",
      "Cost:  9018.72886277375\n",
      "Cost:  9012.843556228796\n",
      "Cost:  9007.315787766041\n",
      "Cost:  9002.119144410253\n",
      "Cost:  8997.22949285434\n",
      "Cost:  8992.624748095075\n",
      "Cost:  8988.284670845402\n",
      "Cost:  8984.190689086545\n",
      "Cost:  8980.325740114547\n",
      "Cost:  8976.67413015926\n",
      "Cost:  8973.221409193557\n",
      "Cost:  8969.954258961607\n",
      "Cost:  8966.860392573948\n",
      "Cost:  8963.928464270168\n",
      "Cost:  8961.14798815392\n",
      "Cost:  8958.509264871882\n",
      "Cost:  8956.003315346063\n",
      "Cost:  8953.621820785373\n",
      "Cost:  8951.357068299547\n",
      "Cost:  8949.201901522963\n",
      "Cost:  8947.149675726449\n",
      "Cost:  8945.194216957527\n",
      "Cost:  8943.329784802647\n",
      "Cost:  8941.551038411419\n",
      "Cost:  8939.853005463057\n",
      "Cost:  8938.231053790869\n",
      "Cost:  8936.680865411263\n",
      "Cost:  8935.198412730946\n",
      "Cost:  8933.779936730176\n",
      "Cost:  8932.421926940435\n",
      "Cost:  8931.121103054153\n",
      "Cost:  8929.874398019936\n",
      "Cost:  8928.678942492012\n",
      "Cost:  8927.532050514877\n",
      "Cost:  8926.431206336389\n",
      "Cost:  8925.374052252137\n",
      "Cost:  8924.358377393792\n",
      "Cost:  8923.38210738153\n",
      "Cost:  8922.443294769033\n",
      "Cost:  8921.54011021499\n",
      "Cost:  8920.670834321874\n",
      "Cost:  8919.833850087693\n",
      "Cost:  8919.027635921071\n",
      "Cost:  8918.250759174893\n",
      "Cost:  8917.501870156877\n",
      "Cost:  8916.779696579832\n",
      "Cost:  8916.083038416684\n",
      "Cost:  8915.410763129245\n",
      "Cost:  8914.761801241182\n",
      "Cost:  8914.135142229246\n",
      "Cost:  8913.529830708021\n",
      "Cost:  8912.944962885946\n",
      "Cost:  8912.379683272164\n",
      "Cost:  8911.833181615122\n",
      "Cost:  8911.304690055766\n",
      "Cost:  8910.793480479042\n",
      "Cost:  8910.298862049221\n",
      "Cost:  8909.82017891537\n",
      "Cost:  8909.356808074277\n",
      "Cost:  8908.908157379703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.90127736,  0.64485452, -0.19692367,  0.8024183 , -2.07712228,\n",
       "        2.39690887,  0.09623137, -2.8998413 ,  2.05202071, -1.16791177,\n",
       "       -2.22286217,  0.58091612, -4.25486376, 22.67689935])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run(learning_rate,iteration):\n",
    "#     row = X_train.shape[0]\n",
    "    col = X_train.shape[1]\n",
    "    m = np.zeros((col))\n",
    "#     for i in range(row):\n",
    "    print(m.shape)\n",
    "    m[13] = 1\n",
    "    for i in range(iteration):\n",
    "        m = step_gradient(learning_rate,m)\n",
    "#         print(\"Cost: \", cost_function(m))\n",
    "    return m\n",
    "m = run(0.1,1000)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989, 2905.6150989,\n",
       "       2905.6150989, 2905.6150989, 2905.6150989])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(m):\n",
    "    y_pred=np.zeros(len(X_test))\n",
    "    for i in range(len(X_test)):\n",
    "        y_pred[i] = (m*X_test).sum()\n",
    "    return y_pred\n",
    "\n",
    "y_pred = predict(m)\n",
    "y_pred\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
