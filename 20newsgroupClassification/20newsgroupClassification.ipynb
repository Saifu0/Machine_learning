{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598411626206",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['alt.atheism',\n 'comp.graphics',\n 'comp.os.ms-windows.misc',\n 'comp.sys.ibm.pc.hardware',\n 'comp.sys.mac.hardware',\n 'comp.windows.x',\n 'misc.forsale',\n 'rec.autos',\n 'rec.motorcycles',\n 'rec.sport.baseball',\n 'rec.sport.hockey',\n 'sci.crypt',\n 'sci.electronics',\n 'sci.med',\n 'sci.space',\n 'soc.religion.christian',\n 'talk.politics.guns',\n 'talk.politics.mideast',\n 'talk.politics.misc',\n 'talk.religion.misc']"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "DIR = \"20_newsgroups\"\n",
    "directories = os.listdir(os.path.join(DIR))\n",
    "directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1000\n"
    }
   ],
   "source": [
    "data = {}\n",
    "for directory in directories:\n",
    "    data[directory] = []\n",
    "    for file in os.listdir(os.path.join(DIR,directory)):\n",
    "        # print(os.path.join(DIR,directory,file))\n",
    "        with open(os.path.join(DIR,directory,file),encoding='latin-1') as f:\n",
    "            data[directory].append(f.read())\n",
    "print(len(data[directories[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "with open('english','r') as file:\n",
    "    words = (file.read().replace('\\n',' '))\n",
    "words = words.split(' ')\n",
    "words\n",
    "stopwords = words + list(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "425357"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "vocabulary = {}\n",
    "for i in data:\n",
    "    for ith_folder in data[i]:\n",
    "        for each_word in ith_folder.split():\n",
    "            if each_word.lower() not in stopwords:\n",
    "                if each_word.lower() not in vocabulary:\n",
    "                    vocabulary[each_word.lower()] = 1\n",
    "                else:\n",
    "                    vocabulary[each_word.lower()] += 1\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "vocab = sorted(vocabulary.items(),key=operator.itemgetter(1),reverse=True)\n",
    "features = []\n",
    "for each in vocab:\n",
    "    features.append(each[0])\n",
    "features = features[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['alt.atheism', 'alt.atheism', 'alt.atheism', 'alt.atheism',\n       'alt.atheism', 'alt.atheism', 'alt.atheism', 'alt.atheism',\n       'alt.atheism', 'alt.atheism'], dtype='<U24')"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "y = []\n",
    "for each in data:\n",
    "    for file in data[each]:\n",
    "        y.append(each)\n",
    "y = np.array(y)\n",
    "y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       subject:  from:  date:  newsgroups:  message-id:  lines:  path:  apr  \\\n0           1.0    1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n1           1.0    1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n2           1.0    1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n3           1.0    1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n4           1.0    1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n...         ...    ...    ...          ...          ...     ...    ...  ...   \n19992       1.0    1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n19993       1.0    1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n19994       1.0    1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n19995       1.0    1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n19996       1.0    1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n\n       organization:  gmt  ...  xterm  >i'm  therefore,  released   ()  \\\n0                1.0  2.0  ...    0.0   0.0         0.0       0.0  0.0   \n1                1.0  2.0  ...    0.0   0.0         0.0       0.0  0.0   \n2                1.0  1.0  ...    0.0   0.0         0.0       0.0  0.0   \n3                1.0  1.0  ...    0.0   0.0         0.0       0.0  0.0   \n4                1.0  1.0  ...    0.0   0.0         0.0       0.0  0.0   \n...              ...  ...  ...    ...   ...         ...       ...  ...   \n19992            1.0  1.0  ...    0.0   0.0         0.0       0.0  0.0   \n19993            1.0  1.0  ...    0.0   0.0         0.0       0.0  0.0   \n19994            1.0  0.0  ...    0.0   0.0         0.0       0.0  0.0   \n19995            1.0  0.0  ...    0.0   0.0         0.0       0.0  0.0   \n19996            1.0  0.0  ...    0.0   0.0         0.0       0.0  0.0   \n\n       constitution  (usa)  ati  attacks  develop  \n0               0.0    0.0  0.0      0.0      0.0  \n1               0.0    0.0  0.0      0.0      0.0  \n2               0.0    0.0  0.0      0.0      0.0  \n3               0.0    0.0  0.0      0.0      0.0  \n4               0.0    0.0  0.0      0.0      0.0  \n...             ...    ...  ...      ...      ...  \n19992           0.0    0.0  0.0      0.0      0.0  \n19993           0.0    0.0  0.0      0.0      0.0  \n19994           0.0    0.0  0.0      0.0      0.0  \n19995           0.0    0.0  0.0      0.0      0.0  \n19996           0.0    0.0  0.0      0.0      0.0  \n\n[19997 rows x 2000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject:</th>\n      <th>from:</th>\n      <th>date:</th>\n      <th>newsgroups:</th>\n      <th>message-id:</th>\n      <th>lines:</th>\n      <th>path:</th>\n      <th>apr</th>\n      <th>organization:</th>\n      <th>gmt</th>\n      <th>...</th>\n      <th>xterm</th>\n      <th>&gt;i'm</th>\n      <th>therefore,</th>\n      <th>released</th>\n      <th>()</th>\n      <th>constitution</th>\n      <th>(usa)</th>\n      <th>ati</th>\n      <th>attacks</th>\n      <th>develop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19992</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>19993</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>19994</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>19997 rows × 2000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=features)\n",
    "\n",
    "for directory in directories:\n",
    "    for file in os.listdir(os.path.join(DIR,directory)):\n",
    "        df.loc[len(df)] = np.zeros(len(features))\n",
    "        with open(os.path.join(DIR,directory,file),encoding='latin-1') as f:\n",
    "            for each in f.read().split():\n",
    "                if each.lower() in features:\n",
    "                    df[each.lower()][len(df)-1] += 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1., 1., 1., ..., 0., 0., 0.],\n       [1., 1., 1., ..., 0., 0., 0.],\n       [1., 1., 1., ..., 0., 0., 0.],\n       ...,\n       [1., 1., 1., ..., 0., 0., 0.],\n       [1., 1., 1., ..., 0., 0., 0.],\n       [1., 1., 1., ..., 0., 0., 0.]])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "X = df.values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,random_state=0,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf=MultinomialNB()\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8078"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x_train,y_train):\n",
    "  result = {}\n",
    "  result[\"total_data\"] = len(y_train)\n",
    "  classes = set(y_train)\n",
    "  for class_ in classes:\n",
    "    result[class_] = {}\n",
    "    rows = (y_train==class_)\n",
    "    x_cur = x_train[rows]\n",
    "    y_cur = y_train[rows]\n",
    "    words =0\n",
    "    for ith_feature in range(len(features)):\n",
    "      result[class_][features[ith_feature]] = x_cur[:,ith_feature].sum()\n",
    "      words += x_cur[:,ith_feature].sum()\n",
    "    result[class_][\"total_words\"] =  words\n",
    "  return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x,label,result):\n",
    "  output = np.log(result[label][\"total_words\"]) - np.log(result[\"total_data\"])\n",
    "  for i in range(len(features)):\n",
    "    current_word_count = result[label][features[i]]+1\n",
    "    total_word_count=result[label][\"total_words\"]+len(features)\n",
    "    current_word_prob = np.log(current_word_count)-np.log(total_word_count)\n",
    "    for j in range(int(x[i])): # if the frequency of word in test data point is zero then we wont consider it.\n",
    "            output+=current_word_prob\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_prediction(x,result):\n",
    "  best_res = -10000\n",
    "  best_class = -10000\n",
    "  ok=True\n",
    "  classes = result.keys()\n",
    "  for class_ in classes:\n",
    "    if class_ == \"total_data\":\n",
    "      continue\n",
    "    prob = prediction(x,class_,result)\n",
    "    if ok or prob > best_res:\n",
    "      best_res = prob\n",
    "      best_class = class_\n",
    "    ok=False\n",
    "  return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_test,result):\n",
    "  y_pred = []\n",
    "  for x in x_test:\n",
    "    y_pred.append(step_prediction(x,result))\n",
    "  return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fit(x_train,y_train)\n",
    "y_pred = predict(x_test,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [233 253 249 240 236 240 261 269 284 248 231 233 244 256 246 252 249 281\n  259 236]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]]\n                          precision    recall  f1-score   support\n\n             alt.atheism       0.00      0.00      0.00         0\n           comp.graphics       0.00      0.00      0.00         0\n comp.os.ms-windows.misc       0.00      0.00      0.00         0\ncomp.sys.ibm.pc.hardware       0.00      0.00      0.00         0\n   comp.sys.mac.hardware       0.00      0.00      0.00         0\n          comp.windows.x       0.00      0.00      0.00         0\n            misc.forsale       0.00      0.00      0.00         0\n               rec.autos       0.00      0.00      0.00         0\n         rec.motorcycles       0.00      0.00      0.00         0\n      rec.sport.baseball       0.00      0.00      0.00         0\n        rec.sport.hockey       0.00      0.00      0.00         0\n               sci.crypt       0.00      0.00      0.00         0\n         sci.electronics       0.00      0.00      0.00         0\n                 sci.med       0.00      0.00      0.00         0\n               sci.space       0.00      0.00      0.00         0\n  soc.religion.christian       0.00      0.00      0.00         0\n      talk.politics.guns       0.00      0.00      0.00         0\n   talk.politics.mideast       0.00      0.00      0.00         0\n      talk.politics.misc       1.00      0.05      0.10      5000\n      talk.religion.misc       0.00      0.00      0.00         0\n\n                accuracy                           0.05      5000\n               macro avg       0.05      0.00      0.00      5000\n            weighted avg       1.00      0.05      0.10      5000\n\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))"
   ]
  }
 ]
}