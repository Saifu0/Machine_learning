{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "#Importing Iris dataset from sklearn\n",
    "iris=datasets.load_iris()\n",
    "\n",
    "#data\n",
    "X_train = iris.data\n",
    "\n",
    "#appending features as 0 based index \n",
    "features = []\n",
    "for each in range(X_train.shape[1]):\n",
    "    features.append(each)\n",
    "    \n",
    "\n",
    "#actual preditions\n",
    "y_ = iris.target\n",
    "y_train = y_\n",
    "\n",
    "#Spliting data and actual prediction i.e df and y into training and testing data with 70-30 ratio\n",
    "# X_train,X_test,y_train,y_test = train_test_split(df,y_,test_size=0.3,random_state=1)\n",
    "print(set(y_train))\n",
    "# y_train\n",
    "iris.target_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing shapes of X_train, y_train, X_test, y_test to get idea of size of data we had...\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to count frequency of label/classes and store in a dictionary\n",
    "def count_freq(y):\n",
    "    classes_freq = {}\n",
    "#     print(y)\n",
    "    for i in y:\n",
    "#         classes_freq[i] += 1\n",
    "        if i not in classes_freq:\n",
    "            classes_freq[i] = 1\n",
    "        else:\n",
    "            classes_freq[i] += 1\n",
    "#     print(classes_freq)\n",
    "    return classes_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find entropy of split\n",
    "def entropy_(y):\n",
    "    hash_ = count_freq(y)\n",
    "    total = len(y)\n",
    "    entropy = 0\n",
    "    for each in hash_:\n",
    "        prob = hash_[each]/total\n",
    "        entropy += (-prob)*math.log2(prob)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion to calculate gain ratio of split\n",
    "def gain_ratio(X,y,feature_id):\n",
    "    #finding entropy before splitiing\n",
    "    info_orginal = entropy_(y)\n",
    "    #extracting unquie labels from feature id \n",
    "    unq = set(X[:,feature_id])\n",
    "    #collecting features and y together\n",
    "    data=pd.DataFrame(X)\n",
    "    data[data.shape[1]] = y\n",
    "    #calculating total number of sample data/data points\n",
    "    total = len(y)\n",
    "    #varibale to store information gain after splitting\n",
    "    info_f=0\n",
    "    #variable to store split info\n",
    "    split_info = 0\n",
    "    #iterating through each unqiue label in feature id \n",
    "    for each in unq:\n",
    "        #collecting only unqiue label X and Y\n",
    "        df = data[data[feature_id]==each]\n",
    "        tot = df.shape[0]\n",
    "        y_values = df[df.shape[1]-1]\n",
    "        info_f += (tot/total)*(entropy_(y_values))\n",
    "        split_info += ((-tot/total)*math.log2(tot/total))\n",
    "    #checking if split info is zero or not, if zero then it will be undefined after dividing it by information gain\n",
    "    if split_info == 0:\n",
    "        return 1000000000\n",
    "    info_gain = info_orginal - info_f\n",
    "    #calculating gain ratio\n",
    "    gain_ratio_ = info_gain/split_info\n",
    "    return gain_ratio_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree steps using recursion\n",
    "def Decision_tree_steps(X,y,features,cnt,classes):\n",
    "    #if tree node contains only one class\n",
    "    if len(set(y))==1:\n",
    "        print(\"Level \",cnt)\n",
    "        for i in classes:\n",
    "            if i in y:\n",
    "                print(\"Count of \",i,\"= \",len(y))\n",
    "            else:\n",
    "                print(\"Count of \",i,\"= \",0)\n",
    "        print(\"Current Entropy is = 0.0\")\n",
    "        print(\"Leaf node\")\n",
    "        print()\n",
    "        return\n",
    "    #if we are out of features to split\n",
    "    if len(features) == 0:\n",
    "        print(\"Level \",cnt)\n",
    "        hash_ = count_freq(y)\n",
    "        max_ = -math.inf\n",
    "        for i in classes:\n",
    "            if i not in hash_:\n",
    "                print(\"Count of \",i,\"= \",0)\n",
    "            else:\n",
    "                max_ = max(hash_[i],max_)\n",
    "                print(\"Count of \",i,\"= \",hash_[i])\n",
    "        print(\"Current Entropy is = \",entropy_(y))\n",
    "        print(\"Lead node\")\n",
    "        print()\n",
    "        return\n",
    "    \n",
    "    #variable to store maximum gain ratio\n",
    "    max_gain = -math.inf\n",
    "    feature_to_choose = None\n",
    "    for feature in features:\n",
    "        current_gain = gain_ratio(X,y,feature)\n",
    "        #if current gain ratio  greater than max gain ratio so far, then update max gain ratio \n",
    "        if current_gain > max_gain:\n",
    "            max_gain = current_gain\n",
    "            feature_to_choose = feature\n",
    "    \n",
    "    print(\"Level \",cnt)\n",
    "    hash_ = count_freq(y)\n",
    "    max_ = -math.inf\n",
    "    \n",
    "    #printing entropy and gain ratio \n",
    "    for class_ in classes:\n",
    "        if class_ not in hash_:\n",
    "            print(\"Count of \",class_,\"= \",0)\n",
    "        else:\n",
    "            max_ = max(hash_[class_],max_)\n",
    "            print(\"Count of \",class_,\"= \",hash_[class_])\n",
    "    print(\"Current Entropy is =\",entropy_(y))\n",
    "    print(\"Splitting on feature  X[\",feature_to_choose,\"] with gain ratio \",max_gain,sep=\"\")\n",
    "    print()\n",
    "    \n",
    "    #extracting unqiue labels from choosen feature\n",
    "    extract_unique = set(X[:,feature_to_choose])\n",
    "    #combining X and y for furthur spliting X and y according to unqiue feature label\n",
    "    data = pd.DataFrame(X)\n",
    "    data[data.shape[1]] = y\n",
    "    \n",
    "    #removing choosen feature since, we don't want to split data with this again\n",
    "    index = features.index(feature_to_choose)\n",
    "    features.remove(feature_to_choose)\n",
    "    \n",
    "    #calling decision tree step furthur for remaining features...\n",
    "    for each in extract_unique:\n",
    "        df = data[data[feature_to_choose]==each]\n",
    "        x_ = df.iloc[:,0:df.shape[1]-1]\n",
    "        y_ = df.iloc[:,df.shape[1]-1]\n",
    "        Decision_tree_steps(x_,y_,features,cnt+1,classes)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2}\n",
      "Level  1\n",
      "Count of  0 =  50\n",
      "Count of  1 =  50\n",
      "Count of  2 =  50\n",
      "Current Entropy is = 1.584962500721156\n",
      "Splitting on feature  X[1] with gain ratio 0.12841651229496967\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  1\n",
      "Count of  1 =  7\n",
      "Count of  2 =  2\n",
      "Current Entropy is =  1.1567796494470395\n",
      "Lead node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  6\n",
      "Count of  1 =  8\n",
      "Count of  2 =  12\n",
      "Current Entropy is =  1.5262349099495225\n",
      "Lead node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  6\n",
      "Count of  1 =  0\n",
      "Count of  2 =  0\n",
      "Current Entropy is = 0.0\n",
      "Leaf node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  5\n",
      "Count of  1 =  3\n",
      "Count of  2 =  5\n",
      "Current Entropy is =  1.5485806065228545\n",
      "Lead node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  3\n",
      "Count of  1 =  0\n",
      "Count of  2 =  1\n",
      "Current Entropy is =  0.8112781244591328\n",
      "Lead node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  4\n",
      "Count of  1 =  3\n",
      "Count of  2 =  4\n",
      "Current Entropy is =  1.5726236638951638\n",
      "Lead node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  0\n",
      "Count of  1 =  0\n",
      "Count of  2 =  0\n",
      "Current Entropy is = 0.0\n",
      "Leaf node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  9\n",
      "Count of  1 =  1\n",
      "Count of  2 =  2\n",
      "Current Entropy is =  1.0408520829727552\n",
      "Lead node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  0\n",
      "Count of  1 =  0\n",
      "Count of  2 =  0\n",
      "Current Entropy is = 0.0\n",
      "Leaf node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  0\n",
      "Count of  1 =  0\n",
      "Count of  2 =  0\n",
      "Current Entropy is = 0.0\n",
      "Leaf node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  0\n",
      "Count of  1 =  0\n",
      "Count of  2 =  0\n",
      "Current Entropy is = 0.0\n",
      "Leaf node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  0\n",
      "Count of  1 =  0\n",
      "Count of  2 =  0\n",
      "Current Entropy is = 0.0\n",
      "Leaf node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  0\n",
      "Count of  1 =  0\n",
      "Count of  2 =  0\n",
      "Current Entropy is = 0.0\n",
      "Leaf node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  0\n",
      "Count of  1 =  4\n",
      "Count of  2 =  4\n",
      "Current Entropy is =  1.0\n",
      "Lead node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  0\n",
      "Count of  1 =  3\n",
      "Count of  2 =  2\n",
      "Current Entropy is =  0.9709505944546686\n",
      "Lead node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  1\n",
      "Count of  1 =  3\n",
      "Count of  2 =  0\n",
      "Current Entropy is =  0.8112781244591328\n",
      "Lead node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  0\n",
      "Count of  1 =  6\n",
      "Count of  2 =  8\n",
      "Current Entropy is =  0.9852281360342516\n",
      "Lead node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  0\n",
      "Count of  1 =  5\n",
      "Count of  2 =  4\n",
      "Current Entropy is =  0.9910760598382222\n",
      "Lead node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  0\n",
      "Count of  1 =  2\n",
      "Count of  2 =  1\n",
      "Current Entropy is =  0.9182958340544896\n",
      "Lead node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  4\n",
      "Count of  1 =  0\n",
      "Count of  2 =  2\n",
      "Current Entropy is =  0.9182958340544896\n",
      "Lead node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  2\n",
      "Count of  1 =  1\n",
      "Count of  2 =  3\n",
      "Current Entropy is =  1.4591479170272448\n",
      "Lead node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  0\n",
      "Count of  1 =  0\n",
      "Count of  2 =  0\n",
      "Current Entropy is = 0.0\n",
      "Leaf node\n",
      "\n",
      "Level  2\n",
      "Count of  0 =  0\n",
      "Count of  1 =  0\n",
      "Count of  2 =  0\n",
      "Current Entropy is = 0.0\n",
      "Leaf node\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pre computing unique class from y\n",
    "classes = set(y_train)\n",
    "print(classes)\n",
    "Decision_tree_steps(X_train,y_train,features,1,classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
